[vars]
ROOT_DIR = /data/gilad/logs/log_0258_011017_wrn_MOM_random_sampler_init_1k_clusters_1k_cap_5k
TRAIN_DIR = ${vars:ROOT_DIR}/train
EVAL_DIR = ${vars:ROOT_DIR}/validation
CHECKPOINT_DIR = ${vars:ROOT_DIR}/checkpoint

DATASET_DIR = /test_dl/data/NEXPARK
TRAIN_IMAGES_DIR       = ${vars:DATASET_DIR}/train/train_data:{vars:DATASET_DIR}/train/images.txt
TAGGED_IMAGES_DIR      = ${vars:DATASET_DIR}/train/train_data:{vars:DATASET_DIR}/train/images_tagged.txt
TRAIN_LABELS_DIR       = ${vars:DATASET_DIR}/train/train_annotations
#TRAIN_LABELS_FILE     = ${vars:DATASET_DIR}/train_labels.txt
VALIDATION_IMAGES_DIR  = ${vars:DATASET_DIR}/test/test_data:${vars:DATASET_DIR}/test/images.txt
VALIDATION_LABELS_DIR  = ${vars:DATASET_DIR}/test/test_annotations
#VALIDATION_LABELS_FILE= ${vars:DATASET_DIR}/test_labels.txt

[self]
DEBUG_MODE = True
SUPERSEED = 3

[self.network]
ARCHITECTURE = Wide-Resnet-28-10
DEVICE = /gpu:0
NUM_CLASSES  = 3
IMAGE_HEIGHT = 32
IMAGE_WIDTH  = 32
NUM_RESIDUAL_UNITS = 4
EMBEDDING_DIMS = 640
BATCH_NORMALIZE_EMBEDDING = False
NORMALIZE_EMBEDDING = True

[self.network.pre_processing]
PREPROCESSOR = preprocessor_drift_flip

[self.network.system]
RELU_LEAKINESS = 0.1

[self.network.optimization]
LEARNING_RATE = 0.1
XENTROPY_RATE = 1.0
WEIGHT_DECAY_RATE = 0.00078125
OPTIMIZER = MOM

[self.dataset]
DATASET_NAME = active_cifar10
DATASET_DIR = ${vars:DATASET_DIR}
TRAIN_SET_SIZE = 50000
VALIDATION_SET_SIZE = 10000
TRAIN_IMAGES_DIR       = ${vars:TRAIN_IMAGES_DIR}
TAGGED_IMAGES_DIR      = ${vars:TAGGED_IMAGES_DIR}
TRAIN_LABELS_DIR       = ${vars:TRAIN_LABELS_DIR}
# TRAIN_LABELS_FILE      = ${vars:TRAIN_LABELS_FILE}
VALIDATION_IMAGES_DIR  = ${vars:VALIDATION_IMAGES_DIR}
VALIDATION_LABELS_DIR  = ${vars:VALIDATION_LABELS_DIR}
# VALIDATION_LABELS_FILE = ${vars:VALIDATION_LABELS_FILE}
STOCHASTIC = False
CLUSTERS = 1000
INIT_SIZE = 1000
CAP = 50000

[self.train]

[self.train.data_augmentation]
FLIP_IMAGE = True
DRIFT_X = 4
DRIFT_Y = 4

[self.train.train_control]
TRAINER = most_uncertained
TRAIN_BATCH_SIZE = 200
EVAL_BATCH_SIZE  = 2200
ROOT_DIR = ${vars:ROOT_DIR}
TRAIN_DIR = ${vars:TRAIN_DIR}
EVAL_DIR = ${vars:EVAL_DIR}
CHECKPOINT_DIR = ${vars:CHECKPOINT_DIR}
SUMMARY_STEPS = 10
CHECKPOINT_SECS = 600
LOGGER_STEPS = 10
EVAL_STEPS = 100
EVALS_IN_EPOCH =
RETENTION_SIZE = 5
MIN_LEARNING_RATE = 0.01
STEPS_FOR_NEW_ANNOTATIONS = [5333, 16000, 32000, 53333]
SKIP_FIRST_EVALUATION = True
PCA_REDUCTION = True
PCA_EMBEDDING_DIMS = 128
ANNOTATION_RULE = fixed_epochs

[self.train.train_control.learning_rate_setter]
LEARNING_RATE_SETTER = decay_by_score
LEARNING_RATE_RESET = 0.1
