[vars]
ROOT_DIR = /data/gilad/logs/log_XXXX_151217_random_sampler_dynamic-SUPERSEED=15121700
TRAIN_DIR = ${vars:ROOT_DIR}/train
EVAL_DIR = ${vars:ROOT_DIR}/validation
PREDICTION_DIR = ${vars:ROOT_DIR}/prediction
CHECKPOINT_DIR = ${vars:ROOT_DIR}/checkpoint

DATASET_DIR = /data/dataset/cifar10
TRAIN_IMAGES_DIR       = ${vars:DATASET_DIR}/train_data
TRAIN_LABELS_FILE      = ${vars:DATASET_DIR}/train_labels.txt
VALIDATION_IMAGES_DIR  = ${vars:DATASET_DIR}/test_data
VALIDATION_LABELS_FILE = ${vars:DATASET_DIR}/test_labels.txt

LR_FACTOR = 5
LR1 = 0.1
LR2 = ${vars:LR1}/${vars:LR_FACTOR}
LR3 = ${vars:LR2}/${vars:LR_FACTOR}
LR4 = ${vars:LR3}/${vars:LR_FACTOR}

[self]
DEBUG_MODE = True
SUPERSEED = 15121700

[self.network]
ARCHITECTURE = Wide-Resnet-28-10
DEVICE = /gpu:0
NUM_CLASSES  = 10
IMAGE_HEIGHT = 32
IMAGE_WIDTH  = 32
NUM_RESIDUAL_UNITS = 4
EMBEDDING_DIMS = 14
NORMALIZE_EMBEDDING = True
RESNET_FILTERS = [2, 4, 6, 14]

[self.network.pre_processing]
PREPROCESSOR = preprocessor_drift_flip

[self.network.system]
RELU_LEAKINESS = 0.1
DROPOUT_KEEP_PROB = 1.0

[self.network.optimization]
LEARNING_RATE = 0.1
XENTROPY_RATE = 1.0
WEIGHT_DECAY_RATE = 0.0390625
OPTIMIZER = MOM

[self.dataset]
DATASET_NAME = active_cifar10
DATASET_DIR = ${vars:DATASET_DIR}
TRAIN_SET_SIZE = 50000
VALIDATION_SET_SIZE = 10000
TRAIN_IMAGES_DIR       = ${vars:TRAIN_IMAGES_DIR}
TRAIN_LABELS_FILE      = ${vars:TRAIN_LABELS_FILE}
VALIDATION_IMAGES_DIR  = ${vars:VALIDATION_IMAGES_DIR}
VALIDATION_LABELS_FILE = ${vars:VALIDATION_LABELS_FILE}
STOCHASTIC = False
CLUSTERS = 1000
INIT_SIZE = 1000
CAP = 5000

[self.train]

[self.train.data_augmentation]
FLIP_IMAGE = True
DRIFT_X = 4
DRIFT_Y = 4

[self.train.train_control]
TRAINER = random_sampler_dynamic
TRAIN_BATCH_SIZE = 200
EVAL_BATCH_SIZE  = 2200
ROOT_DIR = ${vars:ROOT_DIR}
TRAIN_DIR = ${vars:TRAIN_DIR}
EVAL_DIR = ${vars:EVAL_DIR}
PREDICTION_DIR = ${vars:PREDICTION_DIR}
CHECKPOINT_DIR = ${vars:CHECKPOINT_DIR}
SUMMARY_STEPS = 1
CHECKPOINT_SECS = 600
CHECKPOINT_STEPS = [15, 35, 40, 70]
LAST_STEP = 101
LOGGER_STEPS = 1
EVAL_STEPS = 20
EVALS_IN_EPOCH =
RETENTION_SIZE = 5
MIN_LEARNING_RATE = 0.01
STEPS_FOR_NEW_ANNOTATIONS = [15, 35, 40, 70]
SKIP_FIRST_EVALUATION = True
PCA_REDUCTION = True
PCA_EMBEDDING_DIMS = 3
ANNOTATION_RULE = fixed_epochs

[self.train.train_control.learning_rate_setter]
LEARNING_RATE_SETTER = fixed_schedule
SCHEDULED_STEPS = [1333, 2666, 4000, 5333, 8000, 10666, 13333, 16000, 20000, 24000, 28000, 32000, 37333, 42666, 48000, 53333, 60000, 66666, 73333]
USE_FIXED_EPOCHS = False
SCHEDULED_LEARNING_RATES = [${vars:LR2}, ${vars:LR3}, ${vars:LR4}, ${vars:LR1}, ${vars:LR2}, ${vars:LR3}, ${vars:LR4}, ${vars:LR1}, ${vars:LR2}, ${vars:LR3}, ${vars:LR4}, ${vars:LR1}, ${vars:LR2}, ${vars:LR3}, ${vars:LR4}, ${vars:LR1}, ${vars:LR2}, ${vars:LR3}, ${vars:LR4}]
DECAY_REFRACTORY_STEPS =
LEARNING_RATE_RESET = 0.1
